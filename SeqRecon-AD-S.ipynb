{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083e3b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# SeqRecon-AD-S: 有监督异常检测（位置感知 Transformer + 二分类头，骨干与 SeqRecon-AD 一致）\n",
    "\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score, precision_score, recall_score\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5174f371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据规模: 8917\n",
      "train=7133, val=892, test=892\n"
     ]
    }
   ],
   "source": [
    "# 1. 数据加载与预处理（与 SeqRecon-AD 一致）\n",
    "\n",
    "card_item = pd.read_csv('card_item.csv')\n",
    "card_feats = pd.read_csv('card_feats.csv', usecols=['label','card_id','name','身份证号','age'])\n",
    "dataset = pd.concat([card_item, card_feats], axis=1)\n",
    "\n",
    "import ast\n",
    "if isinstance(dataset['明细项目名称'].iloc[0], str):\n",
    "    dataset['明细项目名称'] = dataset['明细项目名称'].apply(ast.literal_eval)\n",
    "\n",
    "print('数据规模:', len(dataset))\n",
    "\n",
    "with open('item2id.json', 'r', encoding='utf-8') as f:\n",
    "    item2id = json.load(f)\n",
    "id2item = {v: k for k, v in item2id.items()}\n",
    "num_items = len(item2id)\n",
    "\n",
    "def map_items_to_ids(items, item2id):\n",
    "    return [item2id[item] for item in items if item in item2id]\n",
    "\n",
    "dataset['明细项目ID'] = dataset['明细项目名称'].apply(lambda x: map_items_to_ids(x, item2id))\n",
    "\n",
    "train_df, temp_df = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "val_df, test_df   = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "print(f\"train={len(train_df)}, val={len(val_df)}, test={len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94bb48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 位置感知 Transformer 骨干 + 二分类头 + next-item 头（多任务 L=L_sup+λ*L_next）\n",
    "\n",
    "class RelativePositionalEncoding(nn.Module):\n",
    "    def __init__(self, num_heads, max_len=512):\n",
    "        super().__init__()\n",
    "        self.rel_pos_table = nn.Parameter(torch.randn(2 * max_len - 1, num_heads))\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, q_len, k_len):\n",
    "        range_q = torch.arange(q_len)[:, None]\n",
    "        range_k = torch.arange(k_len)[None, :]\n",
    "        distance_mat = range_k - range_q\n",
    "        distance_mat = distance_mat.clamp(-self.max_len + 1, self.max_len - 1)\n",
    "        distance_mat += self.max_len - 1\n",
    "        rel_bias = self.rel_pos_table[distance_mat]\n",
    "        rel_bias = rel_bias.permute(2, 0, 1)\n",
    "        return rel_bias\n",
    "\n",
    "\n",
    "class RelativeMultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None, pos_bias=None):\n",
    "        B, L, D = query.shape\n",
    "        H = self.num_heads\n",
    "        d = D // H\n",
    "        q = self.q_proj(query).view(B, L, H, d).transpose(1, 2)\n",
    "        k = self.k_proj(key).view(B, L, H, d).transpose(1, 2)\n",
    "        v = self.v_proj(value).view(B, L, H, d).transpose(1, 2)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d)\n",
    "        if pos_bias is not None:\n",
    "            scores = scores + pos_bias.unsqueeze(0)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores + attn_mask.unsqueeze(0).unsqueeze(0)\n",
    "        if key_padding_mask is not None:\n",
    "            scores = scores.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf'))\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_weights = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "        attn_output = torch.matmul(attn_weights, v)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, L, D)\n",
    "        return self.out_proj(attn_output)\n",
    "\n",
    "\n",
    "class CustomTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.self_attn = RelativeMultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(d_model, d_model * 4)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_model * 4, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None, pos_bias=None):\n",
    "        src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n",
    "                              key_padding_mask=src_key_padding_mask, pos_bias=pos_bias)\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "        src2 = self.linear2(self.dropout(F.relu(self.linear1(src))))\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src\n",
    "\n",
    "\n",
    "class TransformerAnomalyDetectorSupervised(nn.Module):\n",
    "    \"\"\"骨干与 SeqRecon-AD 一致，二分类头 + next-item 头；多任务 L=L_sup+λ*L_next\"\"\"\n",
    "    def __init__(self, embedding_matrix, d_model=512, nhead=4, num_layers=6, dropout=0.2, pad_idx=0):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "        num_items, embedding_dim = embedding_matrix.size()\n",
    "        embedding_matrix = (embedding_matrix - embedding_matrix.mean()) / (embedding_matrix.std() + 1e-8)\n",
    "\n",
    "        self.embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(embedding_matrix)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.embed_proj = nn.Linear(embedding_dim, d_model)\n",
    "        self.pos_encoder = RelativePositionalEncoding(num_heads=nhead, max_len=512)\n",
    "        self.layers = nn.ModuleList([\n",
    "            CustomTransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        self.predictor = nn.Linear(d_model, num_items)\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, 2),\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.embed_proj.bias.data.zero_()\n",
    "        self.embed_proj.weight.data.uniform_(-initrange, initrange)\n",
    "        nn.init.xavier_uniform_(self.predictor.weight)\n",
    "        self.predictor.bias.data.zero_()\n",
    "        for m in self.cls_head:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def generate_mask(self, seq_len, device):\n",
    "        mask = (torch.triu(torch.ones(seq_len, seq_len)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, 0.0)\n",
    "        return mask.to(device)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        B, L = src.size()\n",
    "        src_emb = self.embedding(src)\n",
    "        src_emb = self.embed_proj(src_emb) * math.sqrt(self.d_model)\n",
    "        src_emb = F.layer_norm(src_emb, src_emb.shape[-1:])\n",
    "\n",
    "        pos_bias = self.pos_encoder(L, L)\n",
    "        src_key_padding_mask = (src == self.pad_idx)\n",
    "\n",
    "        output = src_emb\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask=src_mask,\n",
    "                           src_key_padding_mask=src_key_padding_mask,\n",
    "                           pos_bias=pos_bias)\n",
    "        output = self.final_norm(output)\n",
    "\n",
    "        predictions = self.predictor(output)\n",
    "        seq_repr = (output * (~src_key_padding_mask).unsqueeze(-1)).sum(1) / (\n",
    "            (~src_key_padding_mask).sum(1, keepdim=True).float().clamp(min=1)\n",
    "        )\n",
    "        cls_logits = self.cls_head(seq_repr)\n",
    "        return predictions, cls_logits\n",
    "\n",
    "    def compute_loss_cls(self, src, labels, mask=None):\n",
    "        _, cls_logits = self.forward(src)\n",
    "        labels = labels.long().clamp(0, 1)\n",
    "        return F.cross_entropy(cls_logits, labels)\n",
    "\n",
    "    def compute_loss_next(self, src, tgt, mask=None):\n",
    "        seq_len = src.size(1)\n",
    "        causal_mask = self.generate_mask(seq_len, src.device)\n",
    "        predictions, _ = self.forward(src, src_mask=causal_mask)\n",
    "        predictions = predictions[:, :-1, :].contiguous()\n",
    "        tgt = tgt[:, 1:].contiguous()\n",
    "        if mask is not None:\n",
    "            mask = mask[:, 1:].contiguous()\n",
    "            active = mask.view(-1) == 1\n",
    "            loss = F.cross_entropy(\n",
    "                predictions.view(-1, predictions.size(-1)), tgt.view(-1), reduction='none'\n",
    "            )\n",
    "            loss = loss[active].mean()\n",
    "        else:\n",
    "            loss = F.cross_entropy(\n",
    "                predictions.view(-1, predictions.size(-1)), tgt.view(-1), ignore_index=self.pad_idx\n",
    "            )\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            return torch.tensor(0.0, device=src.device, dtype=loss.dtype)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab01b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dataset / DataLoader（与 SeqRecon-AD 一致）\n",
    "\n",
    "class PrescriptionDataset(Dataset):\n",
    "    def __init__(self, dataframe, max_length=517, pad_idx=0):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.max_length = max_length\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.data.iloc[idx]['明细项目ID']\n",
    "        if len(sequence) > self.max_length:\n",
    "            sequence = sequence[:self.max_length]\n",
    "            original_len = self.max_length\n",
    "        else:\n",
    "            original_len = len(sequence)\n",
    "            sequence = sequence + [self.pad_idx] * (self.max_length - len(sequence))\n",
    "        input_seq = target_seq = sequence\n",
    "        mask = [1] * original_len + [0] * (self.max_length - original_len)\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        return {\n",
    "            'input_seq': torch.tensor(input_seq, dtype=torch.long),\n",
    "            'target_seq': torch.tensor(target_seq, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.float),\n",
    "            'label': torch.tensor(label, dtype=torch.float),\n",
    "        }\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    input_seqs = torch.stack([b['input_seq'] for b in batch])\n",
    "    target_seqs = torch.stack([b['target_seq'] for b in batch])\n",
    "    masks = torch.stack([b['mask'] for b in batch])\n",
    "    labels = torch.stack([b['label'] for b in batch])\n",
    "    return {'input_seq': input_seqs, 'target_seq': target_seqs, 'mask': masks, 'label': labels}\n",
    "\n",
    "\n",
    "train_dataset = PrescriptionDataset(train_df)\n",
    "val_dataset   = PrescriptionDataset(val_df)\n",
    "test_dataset  = PrescriptionDataset(test_df)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  collate_fn=custom_collate_fn)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90eca14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 评估函数：分类指标 + Recall@10/NDCG@10；F1 阈值可在验证集上优化\n",
    "\n",
    "def evaluate_retrieval(model, data_loader, device, k=10):\n",
    "    \"\"\"Next-item 检索：Recall@k, NDCG@k\"\"\"\n",
    "    model.eval()\n",
    "    total_recall, total_ndcg, total_cnt = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_seq = batch['input_seq'].to(device)\n",
    "            target_seq = batch['target_seq'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            B, L = input_seq.size()\n",
    "            causal_mask = model.generate_mask(L, device)\n",
    "            logits, _ = model(input_seq, src_mask=causal_mask)\n",
    "            last_logits = logits[:, -1, :].clone()\n",
    "            last_logits[:, 0] = -float('inf')\n",
    "            _, topk_indices = torch.topk(last_logits, k=k, dim=-1)\n",
    "            lengths = mask.sum(dim=1).long()\n",
    "            next_indices = (lengths - 1).clamp(min=0)\n",
    "            next_item = target_seq.gather(1, next_indices.view(-1, 1)).squeeze(1)\n",
    "            gt = next_item.cpu().numpy()\n",
    "            pred = topk_indices.cpu().numpy()\n",
    "            for g, p in zip(gt, pred):\n",
    "                if np.any(p == g):\n",
    "                    total_recall += 1.0\n",
    "                    rank = np.where(p == g)[0][0] + 1\n",
    "                    total_ndcg += 1.0 / math.log2(rank + 1)\n",
    "                total_cnt += 1\n",
    "    return total_recall / total_cnt, total_ndcg / total_cnt\n",
    "\n",
    "\n",
    "def get_probs_and_labels(model, data_loader, device):\n",
    "    \"\"\"获取模型在 data_loader 上的异常类概率与真实标签（用于阈值搜索）\"\"\"\n",
    "    model.eval()\n",
    "    all_logits, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_seq = batch['input_seq'].to(device)\n",
    "            _, cls_logits = model(input_seq)\n",
    "            all_logits.append(cls_logits.cpu().numpy())\n",
    "            all_labels.append(batch['label'].numpy())\n",
    "    probs = torch.softmax(torch.tensor(np.concatenate(all_logits)), dim=-1)[:, 1].numpy()\n",
    "    labels = np.concatenate(all_labels)\n",
    "    return probs, labels\n",
    "\n",
    "\n",
    "def get_best_f1_threshold(probs, labels, num_steps=101):\n",
    "    \"\"\"在 [0,1] 上搜索使 F1 最大的阈值，与 SeqRecon-AD 等统一可比\"\"\"\n",
    "    best_threshold, best_f1 = 0.5, 0.0\n",
    "    best_precision, best_recall = 0.0, 0.0\n",
    "    for i in range(num_steps):\n",
    "        thresh = i / (num_steps - 1) if num_steps > 1 else 0.5\n",
    "        pred = (probs >= thresh).astype(int)\n",
    "        p = precision_score(labels, pred, zero_division=0)\n",
    "        r = recall_score(labels, pred, zero_division=0)\n",
    "        f1 = f1_score(labels, pred, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = thresh\n",
    "            best_precision, best_recall = p, r\n",
    "    return best_threshold, best_f1, best_precision, best_recall\n",
    "\n",
    "\n",
    "def evaluate_cls(model, data_loader, device, threshold=0.5):\n",
    "    \"\"\"仅分类指标：AUC, PR-AUC, Precision, Recall, F1（有监督异常检测）。\"\"\"\n",
    "    model.eval()\n",
    "    all_cls_logits = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_seq = batch['input_seq'].to(device)\n",
    "            _, cls_logits = model(input_seq)\n",
    "            all_cls_logits.append(cls_logits.cpu().numpy())\n",
    "            all_labels.append(batch['label'].numpy())\n",
    "    all_cls_logits = np.concatenate(all_cls_logits, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    probs = torch.softmax(torch.tensor(all_cls_logits), dim=-1)[:, 1].numpy()\n",
    "    pred_labels = (probs >= threshold).astype(int)\n",
    "    return {\n",
    "        'AUC': roc_auc_score(all_labels, probs),\n",
    "        'PR_AUC': auc(precision_recall_curve(all_labels, probs)[1], precision_recall_curve(all_labels, probs)[0]),\n",
    "        'Precision': precision_score(all_labels, pred_labels, zero_division=0),\n",
    "        'Recall': recall_score(all_labels, pred_labels, zero_division=0),\n",
    "        'F1': f1_score(all_labels, pred_labels, zero_division=0),\n",
    "        'threshold_used': threshold,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ae3dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 有监督训练循环：仅二分类损失（有监督异常检测），按验证集 F1 保存最佳\n",
    "\n",
    "import copy\n",
    "\n",
    "def train_supervised(model, train_loader, val_loader, device,\n",
    "                     max_epochs=50, patience=5, lambda_next=0.0,\n",
    "                     save_path='seqrecon_supervised_best.pt'):\n",
    "    \"\"\"L = L_sup + λ*L_next；lambda_next=0 即仅分类。\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9)\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_state = None\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_batches = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch}/{max_epochs}'):\n",
    "            input_seq = batch['input_seq'].to(device)\n",
    "            target_seq = batch['target_seq'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            L_sup = model.compute_loss_cls(input_seq, labels, mask)\n",
    "            L_next = model.compute_loss_next(input_seq, target_seq, mask) if lambda_next != 0 else torch.tensor(0.0, device=device)\n",
    "            loss = L_sup + lambda_next * L_next\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / total_batches\n",
    "\n",
    "        model.eval()\n",
    "        val_probs, val_labels = get_probs_and_labels(model, val_loader, device)\n",
    "        best_thresh, best_f1_at_thresh, _, _ = get_best_f1_threshold(val_probs, val_labels)\n",
    "        val_metrics = evaluate_cls(model, val_loader, device, threshold=0.5)\n",
    "\n",
    "        print(f'Epoch {epoch} Completed, Avg Loss: {avg_loss:.4f}')\n",
    "        print(f'Val AUC: {val_metrics[\"AUC\"]:.4f}, PR-AUC: {val_metrics[\"PR_AUC\"]:.4f}, '\n",
    "              f'F1@0.5: {val_metrics[\"F1\"]:.4f} | F1@best: {best_f1_at_thresh:.4f} (thr={best_thresh:.3f})')\n",
    "\n",
    "        if best_f1_at_thresh > best_f1:\n",
    "            best_f1 = best_f1_at_thresh\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_state, save_path)\n",
    "            print('Saved new best model (by F1 at optimal threshold)')\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f'Early stopping at epoch {epoch}')\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212485e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108321/3116511911.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_emb.load_state_dict(torch.load('item_embedding.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== λ = 0.8 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150: 100%|██████████| 112/112 [01:25<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Completed, Avg Loss: 5.9967\n",
      "Val AUC: 0.5847, PR-AUC: 0.2593, F1@0.5: 0.0000 | F1@best: 0.3348 (thr=0.160)\n",
      "Saved new best model (by F1 at optimal threshold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150: 100%|██████████| 112/112 [01:24<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Completed, Avg Loss: 5.2976\n",
      "Val AUC: 0.6573, PR-AUC: 0.3639, F1@0.5: 0.0000 | F1@best: 0.3379 (thr=0.130)\n",
      "Saved new best model (by F1 at optimal threshold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/150: 100%|██████████| 112/112 [01:24<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Completed, Avg Loss: 5.1767\n",
      "Val AUC: 0.7122, PR-AUC: 0.3680, F1@0.5: 0.0000 | F1@best: 0.4643 (thr=0.150)\n",
      "Saved new best model (by F1 at optimal threshold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150:  46%|████▌     | 51/112 [00:38<00:46,  1.31it/s]"
     ]
    }
   ],
   "source": [
    "# 8. 多任务权重 λ 实验：L = L_sup + λ*L_next，分析 next-item 辅助任务对弱监督检测性能的影响\n",
    "# λ ∈ {0, 0.1, 0.3, 0.5, 0.8, 1.0}，骨干与训练配置固定\n",
    "\n",
    "import gc\n",
    "\n",
    "LAMBDA_VALUES = [0.8,1.5]\n",
    "max_epochs = 150\n",
    "patience = 10\n",
    "results_lambda = []\n",
    "\n",
    "embedding_dim = 4096\n",
    "pretrained_emb = nn.Embedding(num_items, embedding_dim)\n",
    "pretrained_emb.load_state_dict(torch.load('item_embedding.pt'))\n",
    "with torch.no_grad():\n",
    "    embedding_matrix = pretrained_emb.weight.clone().detach()\n",
    "\n",
    "for lam in LAMBDA_VALUES:\n",
    "    print(f'\\n========== λ = {lam} ==========')\n",
    "    save_path = f'seqrecon_supervised_lambda_{lam}.pt'\n",
    "    model_lam = TransformerAnomalyDetectorSupervised(\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        d_model=512, nhead=2, num_layers=8, dropout=0.1, pad_idx=0,\n",
    "    ).to(device)\n",
    "    model_lam = train_supervised(\n",
    "        model_lam,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        max_epochs=max_epochs,\n",
    "        patience=patience,\n",
    "        lambda_next=lam,\n",
    "        save_path=save_path,\n",
    "    )\n",
    "    model_lam.load_state_dict(torch.load(save_path))\n",
    "    model_lam.eval()\n",
    "    # Avg_Loss (L_sup + λ*L_next) on test\n",
    "    test_loss_sum, test_n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inp = batch['input_seq'].to(device)\n",
    "            tgt = batch['target_seq'].to(device)\n",
    "            m = batch['mask'].to(device)\n",
    "            lab = batch['label'].to(device)\n",
    "            L_sup = model_lam.compute_loss_cls(inp, lab, m)\n",
    "            L_next = model_lam.compute_loss_next(inp, tgt, m)\n",
    "            test_loss_sum += (L_sup.item() + lam * L_next.item()) * inp.size(0)\n",
    "            test_n += inp.size(0)\n",
    "    avg_loss = test_loss_sum / max(test_n, 1)\n",
    "    recall10, ndcg10 = evaluate_retrieval(model_lam, test_loader, device, k=10)\n",
    "    val_probs, val_labels = get_probs_and_labels(model_lam, val_loader, device)\n",
    "    best_threshold, best_f1_val, _, _ = get_best_f1_threshold(val_probs, val_labels)\n",
    "    test_metrics = evaluate_cls(model_lam, test_loader, device, threshold=best_threshold)\n",
    "    results_lambda.append({\n",
    "        'lambda': lam,\n",
    "        'Avg_Loss': round(avg_loss, 4),\n",
    "        'Recall@10': round(recall10, 4),\n",
    "        'NDCG@10': round(ndcg10, 4),\n",
    "        'AUC': round(test_metrics['AUC'], 4),\n",
    "        'PR-AUC': round(test_metrics['PR_AUC'], 4),\n",
    "        'F1': round(test_metrics['F1'], 4),\n",
    "        'Precision': round(test_metrics['Precision'], 4),\n",
    "        'Recall': round(test_metrics['Recall'], 4),\n",
    "    })\n",
    "    print(results_lambda)\n",
    "    del model_lam\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "cols = ['lambda', 'Avg_Loss', 'Recall@10', 'NDCG@10', 'AUC', 'PR-AUC', 'F1', 'Precision', 'Recall']\n",
    "lambda_df = pd.DataFrame(results_lambda)[cols]\n",
    "print('\\\\n========== 多任务权重 λ 对弱监督检测性能的影响 ==========')\n",
    "display(lambda_df)\n",
    "lambda_df.to_csv('SeqRecon_AD_S_lambda_ablation-v2.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b08dc5-eb8b-489e-a273-71874e168a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gad_env",
   "language": "python",
   "name": "gad_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
