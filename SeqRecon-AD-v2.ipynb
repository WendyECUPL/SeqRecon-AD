{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a31efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# SeqRecon-AD-v2: 无监督序列重构异常检测（新完整模型）\n",
    "# 相对原 Full：finetune embedding + 无 self-clean，异常分数不做账户内 z-score 标准化\n",
    "\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score, precision_score, recall_score\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda92e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据规模: 8917\n",
      "train=7133, val=892, test=892\n"
     ]
    }
   ],
   "source": [
    "# 1. 数据加载与预处理（与 SeqRecon-AD 一致）\n",
    "\n",
    "card_item = pd.read_csv('card_item.csv')\n",
    "card_feats = pd.read_csv('card_feats.csv', usecols=['label','card_id','name','身份证号','age'])\n",
    "dataset = pd.concat([card_item, card_feats], axis=1)\n",
    "\n",
    "import ast\n",
    "if isinstance(dataset['明细项目名称'].iloc[0], str):\n",
    "    dataset['明细项目名称'] = dataset['明细项目名称'].apply(ast.literal_eval)\n",
    "\n",
    "print('数据规模:', len(dataset))\n",
    "\n",
    "with open('item2id.json', 'r', encoding='utf-8') as f:\n",
    "    item2id = json.load(f)\n",
    "id2item = {v: k for k, v in item2id.items()}\n",
    "num_items = len(item2id)\n",
    "\n",
    "def map_items_to_ids(items, item2id):\n",
    "    return [item2id[item] for item in items if item in item2id]\n",
    "\n",
    "dataset['明细项目ID'] = dataset['明细项目名称'].apply(lambda x: map_items_to_ids(x, item2id))\n",
    "\n",
    "train_df, temp_df = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "val_df, test_df   = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "print(f\"train={len(train_df)}, val={len(val_df)}, test={len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26410273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerAnomalyDetectorV2 ready.\n"
     ]
    }
   ],
   "source": [
    "# 2. 位置感知 Transformer（无监督 next-item）；v2：embedding 可微调，异常分数不 z-score\n",
    "\n",
    "class RelativePositionalEncoding(nn.Module):\n",
    "    def __init__(self, num_heads, max_len=512):\n",
    "        super().__init__()\n",
    "        self.rel_pos_table = nn.Parameter(torch.randn(2 * max_len - 1, num_heads))\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, q_len, k_len):\n",
    "        range_q = torch.arange(q_len)[:, None]\n",
    "        range_k = torch.arange(k_len)[None, :]\n",
    "        distance_mat = range_k - range_q\n",
    "        distance_mat = distance_mat.clamp(-self.max_len + 1, self.max_len - 1)\n",
    "        distance_mat += self.max_len - 1\n",
    "        rel_bias = self.rel_pos_table[distance_mat].permute(2, 0, 1)\n",
    "        return rel_bias\n",
    "\n",
    "\n",
    "class RelativeMultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None, pos_bias=None):\n",
    "        B, L, D = query.shape\n",
    "        H, d = self.num_heads, D // self.num_heads\n",
    "        q = self.q_proj(query).view(B, L, H, d).transpose(1, 2)\n",
    "        k = self.k_proj(key).view(B, L, H, d).transpose(1, 2)\n",
    "        v = self.v_proj(value).view(B, L, H, d).transpose(1, 2)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d)\n",
    "        if pos_bias is not None:\n",
    "            scores = scores + pos_bias.unsqueeze(0)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores + attn_mask.unsqueeze(0).unsqueeze(0)\n",
    "        if key_padding_mask is not None:\n",
    "            scores = scores.masked_fill(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf'))\n",
    "        attn_weights = F.dropout(torch.softmax(scores, dim=-1), p=self.dropout, training=self.training)\n",
    "        out = torch.matmul(attn_weights, v).transpose(1, 2).contiguous().view(B, L, D)\n",
    "        return self.out_proj(out)\n",
    "\n",
    "\n",
    "class CustomTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.self_attn = RelativeMultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(d_model, d_model * 4)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_model * 4, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None, pos_bias=None):\n",
    "        src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n",
    "                              key_padding_mask=src_key_padding_mask, pos_bias=pos_bias)\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "        src = src + self.dropout2(self.linear2(F.relu(self.linear1(src))))\n",
    "        return self.norm2(src)\n",
    "\n",
    "\n",
    "class TransformerAnomalyDetectorV2(nn.Module):\n",
    "    \"\"\"无监督 v2：finetune embedding + 无 self-clean；异常分数不做账户内 z-score（use_score_norm=False），Top-K 聚合。\"\"\"\n",
    "    def __init__(self, embedding_matrix, d_model=512, nhead=4, num_layers=6, dropout=0.2, pad_idx=0, freeze_embedding=False):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pad_idx = pad_idx\n",
    "        self.use_score_norm = False\n",
    "        self.use_topk_agg = True\n",
    "\n",
    "        num_items, embedding_dim = embedding_matrix.size()\n",
    "        emb = (embedding_matrix - embedding_matrix.mean()) / (embedding_matrix.std() + 1e-8)\n",
    "        self.embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(emb.clone().detach())\n",
    "        self.embedding.weight.requires_grad = not freeze_embedding\n",
    "\n",
    "        self.embed_proj = nn.Linear(embedding_dim, d_model)\n",
    "        self.pos_encoder = RelativePositionalEncoding(num_heads=nhead, max_len=512)\n",
    "        self.layers = nn.ModuleList([\n",
    "            CustomTransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        self.predictor = nn.Linear(d_model, num_items)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.embed_proj.bias.data.zero_()\n",
    "        self.embed_proj.weight.data.uniform_(-initrange, initrange)\n",
    "        nn.init.xavier_uniform_(self.predictor.weight)\n",
    "        self.predictor.bias.data.zero_()\n",
    "\n",
    "    def generate_mask(self, seq_len, device):\n",
    "        m = (torch.triu(torch.ones(seq_len, seq_len)) == 1).transpose(0, 1)\n",
    "        m = m.float().masked_fill(m == 0, float('-inf')).masked_fill(m == 1, 0.0)\n",
    "        return m.to(device)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        B, L = src.size()\n",
    "        src_emb = self.embedding(src)\n",
    "        src_emb = self.embed_proj(src_emb) * math.sqrt(self.d_model)\n",
    "        src_emb = F.layer_norm(src_emb, src_emb.shape[-1:])\n",
    "        pos_bias = self.pos_encoder(L, L)\n",
    "        pad_mask = (src == self.pad_idx)\n",
    "        out = src_emb\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, src_mask=src_mask, src_key_padding_mask=pad_mask, pos_bias=pos_bias)\n",
    "        return self.predictor(self.final_norm(out))\n",
    "\n",
    "    def compute_loss(self, src, tgt, mask=None):\n",
    "        seq_len = src.size(1)\n",
    "        causal_mask = self.generate_mask(seq_len, src.device)\n",
    "        predictions = self.forward(src, src_mask=causal_mask)[:, :-1, :].contiguous()\n",
    "        tgt = tgt[:, 1:].contiguous()\n",
    "        if mask is not None:\n",
    "            mask = mask[:, 1:].contiguous()\n",
    "            loss = F.cross_entropy(predictions.view(-1, predictions.size(-1)), tgt.view(-1), reduction='none')\n",
    "            loss = loss[mask.view(-1) == 1].mean()\n",
    "        else:\n",
    "            loss = F.cross_entropy(predictions.view(-1, predictions.size(-1)), tgt.view(-1), ignore_index=self.pad_idx)\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            return torch.tensor(0.0, requires_grad=True).to(loss.device)\n",
    "        return loss\n",
    "\n",
    "    def compute_anomaly_score(self, sequences, mask=None, topk_ratio=0.2, return_token_level=False):\n",
    "        with torch.no_grad():\n",
    "            seq_len = sequences.size(1)\n",
    "            causal_mask = self.generate_mask(seq_len, sequences.device)\n",
    "            predictions = self.forward(sequences, src_mask=causal_mask)[:, :-1, :].contiguous()\n",
    "            targets = sequences[:, 1:].contiguous()\n",
    "            per_position_loss = F.cross_entropy(\n",
    "                predictions.view(-1, predictions.size(-1)), targets.view(-1), reduction='none'\n",
    "            ).view_as(targets)\n",
    "            if mask is not None:\n",
    "                mask_cut = mask[:, 1:].contiguous()\n",
    "                per_position_loss = per_position_loss * mask_cut\n",
    "            if self.use_score_norm:\n",
    "                mean = per_position_loss.mean(dim=1, keepdim=True)\n",
    "                std = per_position_loss.std(dim=1, keepdim=True) + 1e-8\n",
    "                normalized_loss = (per_position_loss - mean) / std\n",
    "            else:\n",
    "                normalized_loss = per_position_loss\n",
    "            if self.use_topk_agg:\n",
    "                k = max(1, int(topk_ratio * (seq_len - 1)))\n",
    "                topk_values, _ = torch.topk(normalized_loss, k=k, dim=1)\n",
    "                scores = topk_values.mean(dim=1)\n",
    "            else:\n",
    "                if mask is not None:\n",
    "                    scores = (normalized_loss * mask_cut).sum(dim=1) / (mask_cut.sum(dim=1) + 1e-8)\n",
    "                else:\n",
    "                    scores = normalized_loss.mean(dim=1)\n",
    "            if return_token_level:\n",
    "                return scores.cpu().numpy(), normalized_loss.cpu().numpy()\n",
    "            return scores.cpu().numpy()\n",
    "\n",
    "print('TransformerAnomalyDetectorV2 ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37dab03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dataset / DataLoader（与 SeqRecon-AD 一致）\n",
    "\n",
    "class PrescriptionDataset(Dataset):\n",
    "    def __init__(self, dataframe, max_length=517, pad_idx=0):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.max_length = max_length\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.data.iloc[idx]['明细项目ID']\n",
    "        if len(sequence) > self.max_length:\n",
    "            sequence = sequence[:self.max_length]\n",
    "            original_len = self.max_length\n",
    "        else:\n",
    "            original_len = len(sequence)\n",
    "            sequence = sequence + [self.pad_idx] * (self.max_length - len(sequence))\n",
    "        mask = [1] * original_len + [0] * (self.max_length - original_len)\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        return {\n",
    "            'input_seq': torch.tensor(sequence, dtype=torch.long),\n",
    "            'target_seq': torch.tensor(sequence, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.float),\n",
    "            'label': torch.tensor(label, dtype=torch.float),\n",
    "        }\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    return {\n",
    "        'input_seq': torch.stack([b['input_seq'] for b in batch]),\n",
    "        'target_seq': torch.stack([b['target_seq'] for b in batch]),\n",
    "        'mask': torch.stack([b['mask'] for b in batch]),\n",
    "        'label': torch.stack([b['label'] for b in batch]),\n",
    "    }\n",
    "\n",
    "train_dataset = PrescriptionDataset(train_df)\n",
    "val_dataset   = PrescriptionDataset(val_df)\n",
    "test_dataset  = PrescriptionDataset(test_df)\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  collate_fn=custom_collate_fn)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9aaa8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 评估函数：Recall@10 / NDCG@10 & 异常检测（AUC, PR-AUC, F1）\n",
    "\n",
    "def evaluate_retrieval(model, data_loader, device, k=10):\n",
    "    model.eval()\n",
    "    total_recall, total_ndcg, total_cnt = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_seq = batch['input_seq'].to(device)\n",
    "            target_seq = batch['target_seq'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            B, L = input_seq.size()\n",
    "            causal_mask = model.generate_mask(L, device)\n",
    "            logits = model(input_seq, src_mask=causal_mask)\n",
    "            last_logits = logits[:, -1, :].clone()\n",
    "            last_logits[:, 0] = -float('inf')\n",
    "            _, topk_indices = torch.topk(last_logits, k=k, dim=-1)\n",
    "            lengths = mask.sum(dim=1).long()\n",
    "            next_indices = (lengths - 1).clamp(min=0)\n",
    "            next_item = target_seq.gather(1, next_indices.view(-1, 1)).squeeze(1)\n",
    "            gt = next_item.cpu().numpy()\n",
    "            pred = topk_indices.cpu().numpy()\n",
    "            for g, p in zip(gt, pred):\n",
    "                if np.any(p == g):\n",
    "                    total_recall += 1.0\n",
    "                    rank = np.where(p == g)[0][0] + 1\n",
    "                    total_ndcg += 1.0 / math.log2(rank + 1)\n",
    "                total_cnt += 1\n",
    "    return total_recall / total_cnt, total_ndcg / total_cnt\n",
    "\n",
    "\n",
    "def evaluate_model_top(model, loader, device, top_percent=0.2):\n",
    "    \"\"\"按固定比例 top_percent 打标异常，返回 AUC/PR-AUC/F1 等\"\"\"\n",
    "    all_scores, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Eval'):\n",
    "            scores = model.compute_anomaly_score(batch['input_seq'].to(device), batch['mask'].to(device), topk_ratio=0.2)\n",
    "            scores = np.nan_to_num(scores, nan=0.0)\n",
    "            all_scores.extend(scores)\n",
    "            all_labels.extend(batch['label'].numpy())\n",
    "    all_scores = np.asarray(all_scores)\n",
    "    all_labels = np.asarray(all_labels)\n",
    "    cutoff = np.percentile(all_scores, 100 * (1 - top_percent))\n",
    "    pred_labels = (all_scores >= cutoff).astype(int)\n",
    "    prec, rec, _ = precision_recall_curve(all_labels, all_scores)\n",
    "    return {\n",
    "        'scores': all_scores,\n",
    "        'labels': all_labels,\n",
    "        'auc': roc_auc_score(all_labels, all_scores),\n",
    "        'pr_auc': auc(rec, prec),\n",
    "        'cutoff': cutoff,\n",
    "        'top_percent': top_percent,\n",
    "        'f1': f1_score(all_labels, pred_labels, zero_division=0),\n",
    "        'precision': precision_score(all_labels, pred_labels, zero_division=0),\n",
    "        'recall': recall_score(all_labels, pred_labels, zero_division=0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf1630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 训练循环：无 self-clean，仅 next-item 损失 + 按 Val Recall@k 早停\n",
    "\n",
    "def train_no_cleaning(model, train_loader, val_loader, device, max_epochs=150, patience=5, batch_size=128, k=10,\n",
    "                      eval_fn=evaluate_retrieval, save_path='seqrecon_v2_best.pt'):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9)\n",
    "    best_recall, best_ndcg, best_result, epochs_no_improve = 0.0, 0.0, None, 0\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        total_loss, total_batches = 0.0, 0\n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{max_epochs}'):\n",
    "            input_seq = batch['input_seq'].to(device)\n",
    "            target_seq = batch['target_seq'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.compute_loss(input_seq, target_seq, mask)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / total_batches\n",
    "        model.eval()\n",
    "        recall_k, ndcg_k = eval_fn(model, val_loader, device, k=k)\n",
    "        print(f'Epoch {epoch+1} Loss: {avg_loss:.4f} Val R@{k}: {recall_k:.4f} NDCG@{k}: {ndcg_k:.4f}')\n",
    "        if recall_k > best_recall:\n",
    "            best_recall, best_ndcg = recall_k, ndcg_k\n",
    "            best_result = {'epoch': epoch+1, 'avg_loss': avg_loss, 'recall': recall_k, 'ndcg': ndcg_k}\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f'Early stop at epoch {epoch+1}.')\n",
    "                break\n",
    "    model.best_result = best_result\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10035d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_453090/3365741221.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_emb.load_state_dict(torch.load('item_embedding.pt'))\n",
      "Epoch 1/150: 100%|██████████| 56/56 [00:43<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 6.7990 Val R@10: 0.1312 NDCG@10: 0.0666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150: 100%|██████████| 56/56 [00:42<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 5.8525 Val R@10: 0.1513 NDCG@10: 0.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/150: 100%|██████████| 56/56 [00:42<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 5.6360 Val R@10: 0.1648 NDCG@10: 0.1042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150: 100%|██████████| 56/56 [00:43<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 5.5407 Val R@10: 0.1827 NDCG@10: 0.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150: 100%|██████████| 56/56 [00:42<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 5.4609 Val R@10: 0.1973 NDCG@10: 0.1238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/150: 100%|██████████| 56/56 [00:43<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 5.3920 Val R@10: 0.2063 NDCG@10: 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/150: 100%|██████████| 56/56 [00:43<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 5.3256 Val R@10: 0.2209 NDCG@10: 0.1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/150: 100%|██████████| 56/56 [00:42<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 5.2601 Val R@10: 0.2287 NDCG@10: 0.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/150: 100%|██████████| 56/56 [00:42<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 5.2051 Val R@10: 0.2410 NDCG@10: 0.1462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/150: 100%|██████████| 56/56 [00:42<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 5.1513 Val R@10: 0.2601 NDCG@10: 0.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/150: 100%|██████████| 56/56 [00:43<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 5.1078 Val R@10: 0.2623 NDCG@10: 0.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/150: 100%|██████████| 56/56 [00:41<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 5.0622 Val R@10: 0.2803 NDCG@10: 0.1682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/150: 100%|██████████| 56/56 [00:40<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 5.0208 Val R@10: 0.2825 NDCG@10: 0.1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/150: 100%|██████████| 56/56 [00:42<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss: 4.9829 Val R@10: 0.2803 NDCG@10: 0.1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/150: 100%|██████████| 56/56 [00:42<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss: 4.9473 Val R@10: 0.2870 NDCG@10: 0.1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/150: 100%|██████████| 56/56 [00:42<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss: 4.9133 Val R@10: 0.2836 NDCG@10: 0.1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/150: 100%|██████████| 56/56 [00:43<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss: 4.8812 Val R@10: 0.2870 NDCG@10: 0.1746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/150: 100%|██████████| 56/56 [00:42<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss: 4.8534 Val R@10: 0.2881 NDCG@10: 0.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/150: 100%|██████████| 56/56 [00:42<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss: 4.8253 Val R@10: 0.3016 NDCG@10: 0.1831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/150: 100%|██████████| 56/56 [00:42<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss: 4.7986 Val R@10: 0.3004 NDCG@10: 0.1816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/150: 100%|██████████| 56/56 [00:41<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Loss: 4.7723 Val R@10: 0.2982 NDCG@10: 0.1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/150: 100%|██████████| 56/56 [00:40<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Loss: 4.7449 Val R@10: 0.3038 NDCG@10: 0.1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/150: 100%|██████████| 56/56 [00:40<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Loss: 4.7263 Val R@10: 0.2971 NDCG@10: 0.1815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/150: 100%|██████████| 56/56 [00:42<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Loss: 4.6992 Val R@10: 0.3128 NDCG@10: 0.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/150: 100%|██████████| 56/56 [00:41<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Loss: 4.6770 Val R@10: 0.3173 NDCG@10: 0.1876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/150: 100%|██████████| 56/56 [00:42<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Loss: 4.6576 Val R@10: 0.3094 NDCG@10: 0.1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/150: 100%|██████████| 56/56 [00:42<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Loss: 4.6359 Val R@10: 0.3128 NDCG@10: 0.1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/150: 100%|██████████| 56/56 [00:41<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Loss: 4.6149 Val R@10: 0.3105 NDCG@10: 0.1869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/150: 100%|██████████| 56/56 [00:41<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Loss: 4.6019 Val R@10: 0.3117 NDCG@10: 0.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/150: 100%|██████████| 56/56 [00:40<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Loss: 4.5801 Val R@10: 0.3139 NDCG@10: 0.1870\n",
      "Early stop at epoch 30.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerAnomalyDetectorV2(\n",
       "  (embedding): Embedding(4119, 4096)\n",
       "  (embed_proj): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (pos_encoder): RelativePositionalEncoding()\n",
       "  (layers): ModuleList(\n",
       "    (0-7): 8 x CustomTransformerEncoderLayer(\n",
       "      (self_attn): RelativeMultiheadAttention(\n",
       "        (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (predictor): Linear(in_features=512, out_features=4119, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 训练入口（finetune embedding + 无 self-clean）\n",
    "\n",
    "embedding_dim = 4096\n",
    "pretrained_emb = nn.Embedding(num_items, embedding_dim)\n",
    "pretrained_emb.load_state_dict(torch.load('item_embedding.pt'))\n",
    "with torch.no_grad():\n",
    "    embedding_matrix = pretrained_emb.weight.clone().detach()\n",
    "\n",
    "model_v2 = TransformerAnomalyDetectorV2(\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    d_model=512,\n",
    "    nhead=2,\n",
    "    num_layers=8,\n",
    "    dropout=0.1,\n",
    "    pad_idx=0,\n",
    "    freeze_embedding=False,\n",
    ").to(device)\n",
    "\n",
    "trained_model = train_no_cleaning(\n",
    "    model_v2,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    max_epochs=150,\n",
    "    patience=5,\n",
    "    batch_size=batch_size,\n",
    "    k=10,\n",
    "    eval_fn=evaluate_retrieval,\n",
    "    save_path='seqrecon_v2_best.pt',\n",
    ")\n",
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72629766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_453090/1114104099.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load('seqrecon_v2_best.pt'))\n",
      "Test Avg_Loss: 100%|██████████| 7/7 [00:02<00:00,  3.48it/s]\n",
      "Eval: 100%|██████████| 7/7 [00:02<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 测试集评测（SeqRecon-AD-v2：finetune emb + 无 self-clean）===\n",
      "Avg_Loss:    5.1027\n",
      "Recall@10:   0.3475\n",
      "NDCG@10:     0.2007\n",
      "AUC:         0.8122\n",
      "PR-AUC:      0.5349\n",
      "Precision:   0.4749\n",
      "Recall:      0.4570\n",
      "F1:          0.4658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 70/70 [00:20<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                card_id name                身份证号  age  \\\n",
      "0  00022092-02fc-45e0-83f2-c51a0d02f2d0  袁**  3101051949********   74   \n",
      "1  000e9b7e-6a96-4eda-947b-425e964e1212  贺**  3101081952********   71   \n",
      "2  000f8286-aa23-42d7-8510-2fab100bcc7b  蒋**  3101081932********   91   \n",
      "3  00117f6c-e739-4913-b453-85a118a47123  刘**  3101021940********   83   \n",
      "4  001c5c03-1db7-4303-934e-21decf219ab1   陈*  3101061948********   75   \n",
      "\n",
      "   anomaly_score  pred_label  \n",
      "0       7.025209           1  \n",
      "1       6.901599           1  \n",
      "2       7.523474           1  \n",
      "3       5.294207           0  \n",
      "4       5.425012           0  \n"
     ]
    }
   ],
   "source": [
    "# 7. 测试集评测（Avg_Loss, Recall@10, NDCG@10, 异常检测指标）与全量推理导出\n",
    "\n",
    "best_model = TransformerAnomalyDetectorV2(\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    d_model=512,\n",
    "    nhead=2,\n",
    "    num_layers=8,\n",
    "    dropout=0.1,\n",
    "    pad_idx=0,\n",
    "    freeze_embedding=False,\n",
    ").to(device)\n",
    "best_model.load_state_dict(torch.load('seqrecon_v2_best.pt'))\n",
    "best_model.eval()\n",
    "\n",
    "test_loss_sum, test_n = 0.0, 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Test Avg_Loss'):\n",
    "        input_seq = batch['input_seq'].to(device)\n",
    "        target_seq = batch['target_seq'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        loss = best_model.compute_loss(input_seq, target_seq, mask)\n",
    "        test_loss_sum += loss.item() * input_seq.size(0)\n",
    "        test_n += input_seq.size(0)\n",
    "avg_loss_test = test_loss_sum / max(test_n, 1)\n",
    "recall10_test, ndcg10_test = evaluate_retrieval(best_model, test_loader, device, k=10)\n",
    "ad_test = evaluate_model_top(best_model, test_loader, device, top_percent=0.2)\n",
    "\n",
    "\n",
    "print('=== 测试集评测（SeqRecon-AD-v2：finetune emb + 无 self-clean）===')\n",
    "print(f'Avg_Loss:    {avg_loss_test:.4f}')\n",
    "print(f'Recall@10:   {recall10_test:.4f}')\n",
    "print(f'NDCG@10:     {ndcg10_test:.4f}')\n",
    "print(f'AUC:         {ad_test[\"auc\"]:.4f}')\n",
    "print(f'PR-AUC:      {ad_test[\"pr_auc\"]:.4f}')\n",
    "print(f'Precision:   {ad_test[\"precision\"]:.4f}')\n",
    "print(f'Recall:      {ad_test[\"recall\"]:.4f}')\n",
    "print(f'F1:          {ad_test[\"f1\"]:.4f}')\n",
    "\n",
    "all_dataset = PrescriptionDataset(dataset)\n",
    "all_loader = DataLoader(all_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate_fn)\n",
    "results = evaluate_model_top(best_model, all_loader, device, top_percent=0.2)\n",
    "cutoff = results['cutoff']\n",
    "all_scores = results['scores']\n",
    "pred_labels = (all_scores >= cutoff).astype(int)\n",
    "\n",
    "base_df = all_dataset.data.reset_index(drop=True)\n",
    "result_df = pd.concat([\n",
    "    base_df[['card_id','name','身份证号','age']].reset_index(drop=True),\n",
    "    pd.Series(all_scores, name='anomaly_score'),\n",
    "    pd.Series(pred_labels, name='pred_label'),\n",
    "], axis=1)\n",
    "print(result_df.head())\n",
    "result_df.to_csv('SeqRecon_AD_v2_scores.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd853a-38b5-418e-843e-c47227676aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gad_env",
   "language": "python",
   "name": "gad_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
